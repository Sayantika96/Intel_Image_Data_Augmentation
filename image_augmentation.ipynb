{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Data Processing with PyTorch: Data Loaders and Augmentation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"In this tutorial, we will explore how to work with data loaders and apply data augmentation techniques using PyTorch. We will use the Intel Image Classification dataset. This dataset contains images of different landforms such as buildings, forest, glacier, mountain, sea, and street.","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Exploration\nFirst, we will import the necessary libraries and load the Intel Image Classification dataset.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nimport os\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:07:26.817557Z","iopub.execute_input":"2024-08-08T07:07:26.818101Z","iopub.status.idle":"2024-08-08T07:07:27.219615Z","shell.execute_reply.started":"2024-08-08T07:07:26.818055Z","shell.execute_reply":"2024-08-08T07:07:27.21842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the path to the dataset\ndata_dir = '/kaggle/input/intel-image-classification'\n\n# Define transformations for the dataset\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Load the dataset\ndataset = ImageFolder(root=os.path.join(data_dir, 'seg_train/seg_train'), transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:06:52.147574Z","iopub.execute_input":"2024-08-08T07:06:52.148043Z","iopub.status.idle":"2024-08-08T07:06:55.12156Z","shell.execute_reply.started":"2024-08-08T07:06:52.148003Z","shell.execute_reply":"2024-08-08T07:06:55.120093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Display the number of images in the dataset\nprint(f\"Number of training images: {train_size}\")\nprint(f\"Number of validation images: {val_size}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some sample images from the dataset\ndef imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get some random training images\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\n\n# Show images\nimshow(torchvision.utils.make_grid(images))","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:07:29.844214Z","iopub.execute_input":"2024-08-08T07:07:29.844822Z","iopub.status.idle":"2024-08-08T07:07:30.606891Z","shell.execute_reply.started":"2024-08-08T07:07:29.844789Z","shell.execute_reply":"2024-08-08T07:07:30.605546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation Techniques\nData augmentation is crucial for training robust models. We will apply various augmentation techniques to our dataset.","metadata":{}},{"cell_type":"code","source":"# Define augmented transformations\naugmented_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.RandomResizedCrop((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:08:40.051002Z","iopub.execute_input":"2024-08-08T07:08:40.051519Z","iopub.status.idle":"2024-08-08T07:08:43.104103Z","shell.execute_reply.started":"2024-08-08T07:08:40.051483Z","shell.execute_reply":"2024-08-08T07:08:43.102641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Horizontal Flip:\n\n* **Description**: This transformation randomly flips the image horizontally with a probability of 0.5. This means that each image has a 50% chance of being flipped.\n\n* **Purpose**: It helps in making the model invariant to the horizontal orientation of the objects in the image, thereby increasing the robustness of the model.\n\n#### Random Rotation:\n\n* **Description**: This transformation rotates the image by a random angle selected from a range of -10 to 10 degrees.\n\n* **Purpose**: It helps the model to learn features irrespective of the rotational orientation of the objects, making the model more robust to rotations.\n\n#### Color Jitter:\n\n* **Description**: This transformation randomly changes the brightness, contrast, saturation, and hue of the image.\n> * Brightness: Adjusts the brightness of the image.\n> * Contrast: Adjusts the contrast of the image.\n> * Saturation: Adjusts the color saturation of the image.\n> Hue: Adjusts the hue (color) of the image.\n\n* **Purpose**: It introduces variations in lighting and color conditions, helping the model to generalize better to different environments and lighting conditions.\n\n#### Random Resized Crop:\n\n* **Description**: This transformation first randomly crops a part of the image and then resizes it to a specified size (128x128 in this case).\n\n* **Purpose**: It helps the model to focus on different parts of the image, thereby learning more diverse features.","metadata":{}},{"cell_type":"code","source":"# Apply the augmented transformations to the training dataset\naugmented_train_dataset = ImageFolder(root=os.path.join(data_dir, 'seg_train/seg_train'), transform=augmented_transform)\n\n# Create a data loader for the augmented dataset\naugmented_train_loader = DataLoader(augmented_train_dataset, batch_size=32, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Custom Data Loaders\nWe will create custom data loaders to handle the original and augmented datasets efficiently.","metadata":{}},{"cell_type":"code","source":"# Function to create data loaders\ndef create_data_loaders(data_dir, batch_size=32, augmented=False):\n    if augmented:\n        transform = augmented_transform\n    else:\n        transform = transforms.Compose([\n            transforms.Resize((128, 128)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n    \n    dataset = ImageFolder(root=data_dir, transform=transform)\n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:08:43.106216Z","iopub.execute_input":"2024-08-08T07:08:43.106613Z","iopub.status.idle":"2024-08-08T07:08:43.381227Z","shell.execute_reply.started":"2024-08-08T07:08:43.106577Z","shell.execute_reply":"2024-08-08T07:08:43.380003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create data loaders for the original and augmented datasets\ntrain_loader, val_loader = create_data_loaders(os.path.join(data_dir, 'seg_train/seg_train'), augmented=False)\naugmented_train_loader, _ = create_data_loaders(os.path.join(data_dir, 'seg_train/seg_train'), augmented=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Augmented Data\nTo better understand the effects of data augmentation, we will visualize some augmented images.","metadata":{}},{"cell_type":"code","source":"# Function to visualize augmented images\ndef visualize_augmented_data(data_loader):\n    dataiter = iter(data_loader)\n    images, labels = next(dataiter)\n    \n    # Show images\n    imshow(torchvision.utils.make_grid(images))\n    # Print labels\n    print(' '.join('%5s' % labels[j].item() for j in range(4)))\n\n# Visualize augmented training data\nvisualize_augmented_data(augmented_train_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:08:57.698487Z","iopub.execute_input":"2024-08-08T07:08:57.698932Z","iopub.status.idle":"2024-08-08T07:08:58.559181Z","shell.execute_reply.started":"2024-08-08T07:08:57.698892Z","shell.execute_reply":"2024-08-08T07:08:58.557478Z"},"trusted":true},"execution_count":null,"outputs":[]}]}